{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# from utilities3 import LpLoss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "import operator\n",
    "from timeit import default_timer\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import deepxde as dde\n",
    "from scipy import linalg\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveBetaFunction(x, gamma, amp):\n",
    "    beta = np.zeros(len(x))\n",
    "    for idx, val in enumerate(x):\n",
    "        beta[idx] = amp*math.cos(gamma*math.acos(val))\n",
    "    return beta\n",
    "\n",
    "def buildF(x, gamma1, amp1, gamma2, amp2):\n",
    "    b1 = solveBetaFunction(x, gamma1, amp1)\n",
    "    b2 = solveBetaFunction(x, gamma2, amp2)\n",
    "    nx = len(x)\n",
    "    f = np.zeros((nx, nx))\n",
    "    for idx, val in enumerate(x):\n",
    "        for idx2, val2 in enumerate(x):\n",
    "            if idx <= idx2:\n",
    "                f[idx][idx2] = b1[idx]*b2[idx2]\n",
    "    return f\n",
    "\n",
    "def buildtau(nx,tau):\n",
    "    tau_matrix = tau * np.ones((nx, nx))\n",
    "    # tau_matrix = np.triu(tau_matrix)\n",
    "    tau_matrix = tau_matrix.reshape(1, -1)\n",
    "    return tau_matrix\n",
    "\n",
    "def buildCof_int_x_1(x, dx):\n",
    "    nx = len(x)\n",
    "    cof_int_x_1 = np.triu(np.ones((nx,nx)))\n",
    "    cof_int_x_1[:,-1]=1/2*np.ones((1,nx))\n",
    "    cof_int_x_1= dx*(cof_int_x_1-1/2*np.eye(nx))\n",
    "    return cof_int_x_1\n",
    "\n",
    "def buildCof_int_0_x(x, dx):\n",
    "    nx = len(x)\n",
    "    cof_int_0_x = np.tril(np.ones((nx,nx)))\n",
    "    cof_int_0_x[:,0]=1/2*np.ones((1,nx))\n",
    "    cof_int_0_x= dx*(cof_int_0_x-1/2*np.eye(nx))\n",
    "    return cof_int_0_x\n",
    "\n",
    "def findinterpolation(kappabud, spatial1, spatial2):\n",
    "    fx = interp1d(spatial1, kappabud, kind=\"cubic\")\n",
    "    kappabudInterp = fx(spatial2)\n",
    "    return kappabudInterp\n",
    "\n",
    "def zeroToNan(x):\n",
    "    for j in range(len(x)):\n",
    "        for i in range(len(x)):\n",
    "            if i > j:\n",
    "                x[i][j] = float('nan')\n",
    "    return x\n",
    "\n",
    "def LowTriTozero(x):\n",
    "    for j in range(len(x)):\n",
    "        for i in range(len(x)):\n",
    "            if i > j:\n",
    "                x[i][j] = float(0)\n",
    "    return x\n",
    "\n",
    "def solveControl(u, Kbud, Lbud, Jbud, nx, dx, tau_obs, k):\n",
    "    return (sum(Kbud*u[0:nx]*dx) +tau_obs*sum(Lbud*u[nx:2*nx]*dx)+k*sum(Jbud*u[2*nx:3*nx]*dx)\n",
    "            - Kbud[0]*u[0]*dx/2\n",
    "            - Kbud[nx-1]*u[nx-1]*dx/2\n",
    "            - tau_obs*Lbud[0]*u[nx]*dx/2\n",
    "            - tau_obs*Lbud[nx-1]*u[2*nx-1]*dx/2\n",
    "            - k*Jbud[0]*u[2*nx]*dx/2\n",
    "            - k*Jbud[nx-1]*u[3*nx-1]*dx/2)\n",
    "\n",
    "def solveOpenLoop(_, _a, _b, _c, _d, _e, _f, _g):\n",
    "    return 0\n",
    "\n",
    "def fastKernelCalc(f, c, tau, tau_obs, x, cof_int_x_1, cof_int_0_x):\n",
    "    nx = len(x) \n",
    "    dx=x[2]-x[1]\n",
    "    k=tau-tau_obs\n",
    "    Ntau=int(tau/dx)+1\n",
    "    K = np.zeros((nx, nx))\n",
    "    result = 0\n",
    "    for i in range(nx-2, -1, -1):\n",
    "        result += (f[[i+1],[i+1]] + f[[i],[i]])*dx/2*(-1)\n",
    "        K[i,i] = result\n",
    "    for i in range(nx-2, -1, -1):\n",
    "        num = nx - i\n",
    "        A1 = np.diag([-2]*num) + np.diag([1]*(num-1),1)\n",
    "        A1[[0],[0]] = 1\n",
    "        A1[[0],[1]] = 0\n",
    "        A1[[-1],[-1]] = 1\n",
    "\n",
    "        A121=np.zeros((num,num))\n",
    "        A122=np.zeros((num,num))\n",
    "        A121[1:num-1,0:num-1]= f.T[i+1:i-1+num,i:i-1+num]\n",
    "        A122[0:num-1,0:num-1] = dx*cof_int_0_x[0:num-1,0:num-1] \n",
    "        A1 = A1+ A121*A122\n",
    "        B1=np.zeros((num,1))\n",
    "        B1[[0],[0]] = K[[i],[i]]\n",
    "        B1[1:num-1,0] =-K[[i+1],i+1:nx-1].reshape((num-2)) +(dx*f[i,i+1:nx-1]).reshape((num-2))\n",
    "        if i+ Ntau<nx:\n",
    "            B1[num-1,0]=sum(cof_int_x_1[i+Ntau-1,:]*K[i+Ntau-1,:]*c)-c[i+Ntau-1]\n",
    "        else:\n",
    "            B1[num-1,0]=0\n",
    "        D=np.linalg.solve(A1,B1)\n",
    "        K[[i],i:nx]=D.T\n",
    "\n",
    "    J=np.zeros((nx, nx))\n",
    "    c_matrix=np.repeat(c[np.newaxis,:], nx, 0)\n",
    "    J[0:nx,0]=np.sum(cof_int_x_1*c_matrix*K, axis=1)-c[0:nx]\n",
    "    AJ = np.diag([k+1]*nx) + np.diag([-1]*(nx-1),-1)\n",
    "    AJ[0,0]=1\n",
    "    for i in range(nx-2, -1, -1):\n",
    "        BJ=np.zeros((nx,1))\n",
    "        BJ[0,0]=J[i,0]\n",
    "        BJ[1:nx,0]=k*J[i+1,1:nx]\n",
    "        J[[i],0:nx]=(np.linalg.solve(AJ,BJ)).T\n",
    "    \n",
    "    L=np.zeros((nx, nx))\n",
    "    L[0:nx,0]=J[0:nx,-1]\n",
    "    AL = np.diag([tau_obs+1]*nx) + np.diag([-1]*(nx-1),-1)\n",
    "    AL[0,0]=1\n",
    "    for i in range(nx-2, -1, -1):\n",
    "        BL=np.zeros((nx,1))\n",
    "        BL[0,0]=L[i,0]\n",
    "        BL[1:nx,0]=tau_obs*L[i+1,1:nx]\n",
    "        L[[i],0:nx]=(np.linalg.solve(AL,BL)).T\n",
    "    return K, L, J\n",
    "\n",
    "def solvePDE(tau, tau_obs, c, f, Kbud, Lbud, Jbud, init_condition, x, t, printFreq=500):\n",
    "    k=tau-tau_obs\n",
    "    nx = len(x)\n",
    "    nt = len(t)\n",
    "    dx=x[1]-x[0]\n",
    "    dt=t[1]-t[0]\n",
    "    uu = np.zeros((nt, 3*nx))\n",
    "    uu[0,:] = init_condition\n",
    "    for i in range(1, nt):\n",
    "        if i%int(1000) == 0:\n",
    "            print(\"Completed:\", i, \"/\", nt, flush=True)\n",
    "            \n",
    "        uu[i][0] = solveControl(uu[i-1], Kbud, Lbud, Jbud, nx, dx,tau_obs,k)\n",
    "        fres = np.zeros(nx)\n",
    "        for j in range(1, nx):\n",
    "            fres[j] = sum(f[j][j:nx]*uu[i-1][j:nx])*dx-f[j][j]*uu[i-1][j]*dx/2-f[j][nx-1]*uu[i-1][nx-1]*dx/2\n",
    "        uu[i][2*nx-1]=uu[i-1][nx-1]\n",
    "        uu[i][nx:2*nx-1] = uu[i-1][nx:2*nx-1]+dt/(tau_obs*dx)*(uu[i-1][nx+1:2*nx]-uu[i-1][nx:2*nx-1])\n",
    "        uu[i][3*nx-1]=uu[i-1][nx]\n",
    "        uu[i][2*nx:3*nx-1] = uu[i-1][2*nx:3*nx-1]+dt/(k*dx)*(uu[i-1][2*nx+1:3*nx]-uu[i-1][2*nx:3*nx-1])\n",
    "        uu[i][1:nx] = uu[i-1][1:nx] - dt/dx*(uu[i-1][1:nx] - uu[i-1][0:nx-1]) + dt*fres[1:nx] + dt*c[1:nx]*uu[i-1][nx]\n",
    "    return uu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(width, fraction=1, subplots=(1, 1), height_add=0):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float or string\n",
    "            Document width in points, or string of predined document type\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    if width == 'thesis':\n",
    "        width_pt = 426.79135\n",
    "    elif width == 'beamer':\n",
    "        width_pt = 307.28987\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = height_add + fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n",
    "\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"times\",\n",
    "    # Use 10pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"font.size\": 10,\n",
    "    # Make the legend/bel fonts a little smaller\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(tex_fonts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time\n",
    "T = 10\n",
    "dt = 0.001\n",
    "nt = int(round(T/dt))+1\n",
    "temporal = np.linspace(0, T, nt)\n",
    "## space\n",
    "X = 1\n",
    "# dx = dt*a\n",
    "dx = 0.02\n",
    "nx = int(round(X/dx))+1\n",
    "spatial = np.linspace(0, X, nx)\n",
    "\n",
    "cof_int_x_1 = buildCof_int_x_1(spatial, dx)\n",
    "cof_int_0_x = buildCof_int_0_x(spatial, dx)\n",
    "\n",
    "## system parameters\n",
    "# tau = 1.8\n",
    "# tau_obs = 0.3\n",
    "# k=tau-tau_obs\n",
    "\n",
    "# c=1-spatial\n",
    "# f =buildF(spatial, 5, 3, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters tranin for JL\n",
    "ndata1 = 10 #tau\n",
    "ndata2 = 10 #tau_obs\n",
    "ndata3 = 10 #f\n",
    "ndata4 = 10 #c\n",
    "ndata=ndata1*ndata2*ndata3*ndata4\n",
    "epochs =300\n",
    "ntrain = 9000\n",
    "ntest = 1000\n",
    "batch_size = 20\n",
    "gamma = 0.6\n",
    "learning_rate = 0.0002\n",
    "step_size= 50\n",
    "# modes=12\n",
    "# width=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset generation for JL\n",
    "inpArr = []\n",
    "outArr = []\n",
    "tauArr = []\n",
    "tauobsArr = []\n",
    "fArr = []\n",
    "cArr = []\n",
    "# # tau=1\n",
    "for i in range(ndata1):\n",
    "        tauArr.append(np.random.uniform(0.8, 2))\n",
    "for i in range(ndata2):\n",
    "        tauobsArr.append(np.random.uniform(0.1, 0.7))\n",
    "for i in range(ndata3):\n",
    "        f = buildF(spatial, np.random.uniform(3, 6), 3, np.random.uniform(3, 6), 3)\n",
    "        fArr.append(f)\n",
    "for i in range(ndata4):\n",
    "        c = solveBetaFunction(spatial, np.random.uniform(3, 6), 1)\n",
    "        c = c-c[-1]\n",
    "        cArr.append(c) \n",
    "jj=0\n",
    "for tau in tauArr:\n",
    "        for tau_obs in tauobsArr:\n",
    "                for f in fArr:\n",
    "                        for c in cArr:\n",
    "                                jj+=1\n",
    "                                if jj % 1000 == 0:\n",
    "                                        print(\"Completed\", jj, \"/\", ndata)\n",
    "                                K,L,J=fastKernelCalc(f, c, tau, tau_obs, spatial, cof_int_x_1, cof_int_0_x)\n",
    "                                tau_matrix=buildtau(nx,tau)\n",
    "                                tauobs_matrix=buildtau(nx,tau_obs)\n",
    "                                c_matrix=buildtau(nx,c)\n",
    "                                tempin=np.concatenate([tauobs_matrix,tau_matrix,f.reshape(1,-1),c_matrix.reshape(1,-1)],axis=1)\n",
    "                                tempout = np.concatenate([K.reshape(1,-1), L.reshape(1,-1), J.reshape(1,-1)],axis=1)\n",
    "                                inpArr.append(tempin)\n",
    "                                outArr.append(tempout)\n",
    "\n",
    "##########\n",
    "x = np.array(inpArr) \n",
    "y = np.array(outArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.reshape(x.shape[0],4*nx*nx)\n",
    "# y = y.reshape(y.shape[0],3*nx*nx)\n",
    "# np.savetxt(\"xlj.dat\", x)\n",
    "# np.savetxt(\"ylj.dat\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpArr = np.loadtxt(\"xlj.dat\", dtype=np.float32)\n",
    "# outArr = np.loadtxt(\"ylj.dat\", dtype=np.float32)\n",
    "# x = np.array(inpArr)\n",
    "# y = np.array(outArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids0 = []\n",
    "grids0.append(np.linspace(0, 1, nx, dtype=np.float32))\n",
    "grids0.append(np.linspace(0, 1, nx, dtype=np.float32))\n",
    "grid0 = np.vstack([xx.ravel() for xx in np.meshgrid(*grids0)]).T\n",
    "grid = torch.from_numpy(grid0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=1)\n",
    "x_train = torch.from_numpy(x_train).cuda()\n",
    "y_train = torch.from_numpy(y_train).cuda()\n",
    "x_test = torch.from_numpy(x_test).cuda()\n",
    "y_test = torch.from_numpy(y_test).cuda()\n",
    "\n",
    "trainData = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "testData = DataLoader(TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False, generator=torch.Generator(device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchNet1(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=64,\n",
    "                       kernel_size=5, stride=2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                       kernel_size=5, stride=2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc1 = torch.nn.Linear(12800, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 256)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x, (x.shape[0], 3, self.shape, self.shape))\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchNet2(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=4, out_channels=64,\n",
    "                       kernel_size=5, stride=2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                       kernel_size=5, stride=2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc1 = torch.nn.Linear(12800, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 256)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x, (x.shape[0], 4, self.shape, self.shape))\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequential torch network for batch and trunk. Can use COV2D which we will show later\n",
    "dim_x = 2\n",
    "# m = int(nx*(nx+1)/2)\n",
    "# m1 = 3*nx*nx\n",
    "m = 4*nx*nx\n",
    "# branchk1 = BranchNet1(nx)\n",
    "branchk2 = BranchNet2(nx)\n",
    "branchk3 = BranchNet2(nx)\n",
    "# modelk1 = dde.nn.DeepONetCartesianProd([m1, branchk1], [dim_x, 128,  256], \"relu\", \"Glorot normal\").cuda()\n",
    "modelk2 = dde.nn.DeepONetCartesianProd([m, branchk2], [dim_x, 128,  256], \"relu\", \"Glorot normal\").cuda()\n",
    "modelk3 = dde.nn.DeepONetCartesianProd([m, branchk3], [dim_x, 128,  256], \"relu\", \"Glorot normal\").cuda()\n",
    "# print(count_params(modelk1))\n",
    "print(count_params(modelk2))\n",
    "print(count_params(modelk3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([  \n",
    "\t{'params': modelk2.parameters(), 'lr': learning_rate,},\n",
    "    {'params': modelk3.parameters(), 'lr': learning_rate,}\n",
    "\t])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "# loss = torch.nn.SmoothL1Loss(reduction='mean', beta=1.0)\n",
    "\n",
    "train_lossArr = []\n",
    "test_lossArr = []\n",
    "time_Arr = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    # modelk1.train()\n",
    "    modelk2.train()\n",
    "    modelk3.train()\n",
    "    t1 = default_timer()\n",
    "    train_loss = 0\n",
    "    for x, y in trainData:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        # x1=x[:,nx*nx:4*nx*nx]\n",
    "        # y1=y[:,0:nx*nx]\n",
    "        y2=y[:,nx*nx:2*nx*nx]\n",
    "        y3=y[:,2*nx*nx:3*nx*nx]\n",
    "        optimizer.zero_grad()\n",
    "        # out1 = modelk1((x1, grid))\n",
    "        out2 = modelk2((x, grid))\n",
    "        out3 = modelk3((x, grid))\n",
    "        lp =  loss(out2.view(batch_size, -1), y2.view(batch_size, -1)) \\\n",
    "        + loss(out3.view(batch_size, -1), y3.view(batch_size, -1))\n",
    "        lp.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += lp.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    # modelk1.eval()\n",
    "    modelk2.eval()\n",
    "    modelk3.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in testData:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            # x1=x[:,nx*nx:4*nx*nx]\n",
    "            # y1=y[:,0:nx*nx]\n",
    "            y2=y[:,nx*nx:2*nx*nx]\n",
    "            y3=y[:,2*nx*nx:3*nx*nx]\n",
    "            # out1 = modelk1((x1, grid))\n",
    "            out2 = modelk2((x, grid))\n",
    "            out3 = modelk3((x, grid))\n",
    "            test_loss +=  loss(out2.view(batch_size, -1), y2.view(batch_size, -1)).item() \\\n",
    "            +loss(out3.view(batch_size, -1), y3.view(batch_size, -1)).item()\n",
    "            \n",
    "    train_loss /= len(trainData)\n",
    "    test_loss /= len(testData)\n",
    "    \n",
    "    train_lossArr.append(train_loss)\n",
    "    test_lossArr.append(test_loss)\n",
    "    \n",
    "    t2 = default_timer()\n",
    "    time_Arr.append(t2-t1)\n",
    "    if ep%50 == 0:\n",
    "        print(ep, t2-t1, np.mean(train_lossArr[-50:]), np.mean(test_lossArr[-50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1000 / 300, 618 / 300), dpi=300)\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.plot(train_lossArr, label=\"Train Loss\",linewidth=1)\n",
    "plt.plot(test_lossArr, label=\"Test Loss\",linewidth=1)\n",
    "\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(fontsize=\"6\")\n",
    "plt.tick_params(labelsize=8)\n",
    "plt.xlabel(r\"$\\mathrm{epoch}$\",fontsize = 8 )\n",
    "# plt.savefig('img/LJloos.eps', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1\n",
    "tau_obs = 0.5\n",
    "k=tau-tau_obs \n",
    "c=solveBetaFunction(spatial, 5, 1)\n",
    "c = c-c[-1]\n",
    "f =buildF(spatial, 5, 3, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshy, meshx = np.meshgrid(spatial, spatial)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(meshx, meshy, zeroToNan(f))\n",
    "ax.set_title(r\"$f(x,y)$\")\n",
    "\n",
    "fig_intep=plt.figure()\n",
    "plt.plot(spatial, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =buildF(spatial, 5, 3, 5, 3)\n",
    "K, L, J=fastKernelCalc(f, c, tau, tau_obs, spatial, cof_int_x_1, cof_int_0_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =buildF(spatial, 5, 3, 5, 3)\n",
    "tau_matrix=buildtau(nx,tau)\n",
    "tauobs_matrix=buildtau(nx,tau_obs)\n",
    "c_matrix=buildtau(nx,c)\n",
    "xdata=np.concatenate([tauobs_matrix,tau_matrix,f.reshape(1,-1),c_matrix.reshape(1,-1)],axis=1)\n",
    " \n",
    "xdata = np.array(xdata, dtype=np.float32)\n",
    "xdata = torch.from_numpy(xdata.reshape((1, 4*nx*nx))).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata1=xdata[:,nx*nx:4*nx*nx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k1= modelk1((xdata1, grid))\n",
    "# k1 = k1.detach().cpu().numpy().reshape(1, nx*nx)\n",
    "# k1=k1.reshape(nx,nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2= modelk2((xdata, grid))\n",
    "k2 = k2.detach().cpu().numpy().reshape(1, nx*nx)\n",
    "k3= modelk3((xdata, grid))\n",
    "k3 = k3.detach().cpu().numpy().reshape(1, nx*nx)\n",
    "k2=k2.reshape(nx,nx)\n",
    "k3=k3.reshape(nx,nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "fig5 = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(meshx, meshy, L)\n",
    "ax.set_title(r\"$L(x,y)$\") \n",
    "ax.set_xlabel(r\"$s$\",fontsize = 5 )\n",
    "ax.set_ylabel(r\"$r$\",fontsize = 5 )\n",
    "ax.set_zlabel(r\"$L(s,r)$\", fontsize = 5 )\n",
    "\n",
    "\n",
    "\n",
    "fig6 = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(meshx, meshy, k2)\n",
    "ax.set_title(r\"$\\hat L(x,y)$\") \n",
    "# ax.set_zticks([-2, 0, 2])\n",
    "fig7 = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(meshx, meshy, L-k2)\n",
    "ax.set_title(r\"$L(x,y)-\\hat L(x,y)$\")\n",
    "# ax.set_zticks([-2, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "fig5 = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(meshx, meshy, J)\n",
    "ax.set_title(r\"$J(x,y)$\")\n",
    "fig6 = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(meshx, meshy, k3)\n",
    "ax.set_title(r\"$\\hat{J}(x,y)$\")\n",
    "fig7 = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(meshx, meshy, J-k3)\n",
    "ax.set_title(r\"$J-\\hat{J}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2='./Model/cftauToCtrlTorchMode2.pth'\n",
    "path3='./Model/cftauToCtrlTorchMode3.pth'\n",
    "torch.save(modelk2.state_dict(), path2)\n",
    "torch.save(modelk3.state_dict(), path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1='./Model/cftauToCtrlTorchMode1.pth' \n",
    "# path2='./Model/cftauToCtrlTorchMode2.pth'\n",
    "# path3='./Model/cftauToCtrlTorchMode3.pth'\n",
    "# modelk1.load_state_dict(torch.load(path1))\n",
    "# modelk2.load_state_dict(torch.load(path2))\n",
    "# modelk3.load_state_dict(torch.load(path3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shr=meshx+tau_obs*meshy\n",
    "skr=meshx+(tau-tau_obs)*meshy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dpi=300\n",
    "LLL_x=np.concatenate([skr[0,:],skr[25,3:51],skr[50,1:51]])\n",
    "LLL_y=np.concatenate([L[0,:],L[25,3:51],L[50,1:51]])\n",
    "LLL_learning_y=np.concatenate([k2[0,:],k2[25,3:51],k2[50,1:51]])\n",
    "fig_intep=plt.figure(figsize=(800 / my_dpi, 500 / my_dpi), dpi=my_dpi)\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.plot(LLL_x, LLL_y,linewidth=1.5,label=r'$L(s)$') \n",
    "plt.plot(LLL_x, LLL_learning_y,linewidth=1.5,linestyle='--',label=r'$\\hat L(s)$') \n",
    "plt.legend(loc=\"upper right\",fontsize=\"8\")\n",
    "# plt.legend(loc=\"best\",fontsize=\"8\")\n",
    "plt.xlabel(r'$\\rm{s}$',fontsize=\"8\")\n",
    "# plt.ylabel(r'$J(s,t) $',fontsize=\"8\")\n",
    "plt.yticks(np.arange(-1,2.5,1))\n",
    "plt.tick_params(labelsize=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.tight_layout()\n",
    "plt.savefig('img/L_sigma.eps', dpi=300,bbox_inches='tight')\n",
    "\n",
    "fig_intep=plt.figure(figsize=(800 / my_dpi, 500 / my_dpi), dpi=my_dpi)\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.plot(LLL_x, LLL_y- LLL_learning_y,linewidth=1.5,label=r'$L(s)-\\hat L(s)$')  \n",
    "# plt.legend(loc=\"upper right\",fontsize=\"8\")\n",
    "# plt.legend(loc=\"best\",fontsize=\"8\")\n",
    "plt.xlabel(r'$\\rm{s}$',fontsize=\"8\")\n",
    "plt.ylabel(r'$L(s)-\\hat L(s) $',fontsize=\"8\")\n",
    "# plt.yticks(np.arange(-0.5,1,0.3))\n",
    "plt.tick_params(labelsize=8)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.tight_layout()\n",
    "plt.savefig('img/L_error_sigma.eps', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dpi=300\n",
    "JJJ_x=np.concatenate([skr[0,:],skr[25,3:51],skr[50,1:51]])\n",
    "JJJ_y=np.concatenate([J[0,:],J[25,3:51],J[50,1:51]])\n",
    "JJJ_learning_y=np.concatenate([k3[0,:],k3[25,3:51],k3[50,1:51]])\n",
    "fig_intep=plt.figure(figsize=(800 / my_dpi, 500 / my_dpi), dpi=my_dpi)\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.plot(JJJ_x, JJJ_y,linewidth=1.5,label=r'$J(s)$') \n",
    "plt.plot(JJJ_x, JJJ_learning_y,linewidth=1.5,linestyle='--',label=r'$\\hat J(s)$') \n",
    "plt.legend(loc=\"upper right\",fontsize=\"8\")\n",
    "# plt.legend(loc=\"best\",fontsize=\"8\")\n",
    "plt.xlabel(r'$\\rm{s}$',fontsize=\"8\")\n",
    "# plt.ylabel(r'$J(s,t) $',fontsize=\"8\")\n",
    "plt.yticks(np.arange(-1,4,1))\n",
    "plt.tick_params(labelsize=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.tight_layout()\n",
    "plt.savefig('img/J_sigma.eps', dpi=300,bbox_inches='tight')\n",
    "\n",
    "fig_intep=plt.figure(figsize=(800 / my_dpi, 500 / my_dpi), dpi=my_dpi)\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.plot(JJJ_x, JJJ_y- JJJ_learning_y,linewidth=1.5,label=r'$J(s)-\\hat J(s)$')  \n",
    "# plt.legend(loc=\"upper right\",fontsize=\"8\")\n",
    "# plt.legend(loc=\"best\",fontsize=\"8\")\n",
    "plt.xlabel(r'$\\rm{s}$',fontsize=\"8\")\n",
    "plt.ylabel(r'$J(s)-\\hat J(s) $',fontsize=\"8\")\n",
    "# plt.yticks(np.arange(-1,1.5,0.5))\n",
    "plt.tick_params(labelsize=8)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.tight_layout()\n",
    "plt.savefig('img/J_error_sigma.eps', dpi=300,bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
