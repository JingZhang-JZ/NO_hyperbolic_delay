{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# from utilities3 import LpLoss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "import operator\n",
    "from timeit import default_timer\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import deepxde as dde\n",
    "from scipy import linalg\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveBetaFunction(x, gamma, amp):\n",
    "    beta = np.zeros(len(x))\n",
    "    for idx, val in enumerate(x):\n",
    "        beta[idx] = amp*math.cos(gamma*math.acos(val))\n",
    "    return beta\n",
    "\n",
    "def buildF(x, gamma1, amp1, gamma2, amp2):\n",
    "    b1 = solveBetaFunction(x, gamma1, amp1)\n",
    "    b2 = solveBetaFunction(x, gamma2, amp2)\n",
    "    nx = len(x)\n",
    "    f = np.zeros((nx, nx))\n",
    "    for idx, val in enumerate(x):\n",
    "        for idx2, val2 in enumerate(x):\n",
    "            if idx <= idx2:\n",
    "                f[idx][idx2] = b1[idx]*b2[idx2]\n",
    "    return f\n",
    "\n",
    "def buildtau(nx,tau):\n",
    "    tau_matrix = tau * np.ones((nx, nx))\n",
    "    # tau_matrix = np.triu(tau_matrix)\n",
    "    tau_matrix = tau_matrix.reshape(1, -1)\n",
    "    return tau_matrix\n",
    "\n",
    "def buildCof_int_x_1(x, dx):\n",
    "    nx = len(x)\n",
    "    cof_int_x_1 = np.triu(np.ones((nx,nx)))\n",
    "    cof_int_x_1[:,-1]=1/2*np.ones((1,nx))\n",
    "    cof_int_x_1= dx*(cof_int_x_1-1/2*np.eye(nx))\n",
    "    return cof_int_x_1\n",
    "\n",
    "def buildCof_int_0_x(x, dx):\n",
    "    nx = len(x)\n",
    "    cof_int_0_x = np.tril(np.ones((nx,nx)))\n",
    "    cof_int_0_x[:,0]=1/2*np.ones((1,nx))\n",
    "    cof_int_0_x= dx*(cof_int_0_x-1/2*np.eye(nx))\n",
    "    return cof_int_0_x\n",
    "\n",
    "def findinterpolation(kappabud, spatial1, spatial2):\n",
    "    fx = interp1d(spatial1, kappabud, kind=\"cubic\")\n",
    "    kappabudInterp = fx(spatial2)\n",
    "    return kappabudInterp\n",
    "\n",
    "def zeroToNan(x):\n",
    "    for j in range(len(x)):\n",
    "        for i in range(len(x)):\n",
    "            if i > j:\n",
    "                x[i][j] = float('nan')\n",
    "    return x\n",
    "\n",
    "def solveControl(u, Kbud, Lbud, Jbud, nx, dx, tau_obs, k):\n",
    "    return (sum(Kbud*u[0:nx]*dx) +tau_obs*sum(Lbud*u[nx:2*nx]*dx)+k*sum(Jbud*u[2*nx:3*nx]*dx)\n",
    "            - Kbud[0]*u[0]*dx/2\n",
    "            - Kbud[nx-1]*u[nx-1]*dx/2\n",
    "            - tau_obs*Lbud[0]*u[nx]*dx/2\n",
    "            - tau_obs*Lbud[nx-1]*u[2*nx-1]*dx/2\n",
    "            - k*Jbud[0]*u[2*nx]*dx/2\n",
    "            - k*Jbud[nx-1]*u[3*nx-1]*dx/2)\n",
    "\n",
    "def solveOpenLoop(_, _a, _b, _c, _d, _e, _f, _g):\n",
    "    return 0\n",
    "\n",
    "def fastKernelCalc(f, c, tau, tau_obs, x, cof_int_x_1, cof_int_0_x):\n",
    "    nx = len(x) \n",
    "    dx=x[2]-x[1]\n",
    "    k=tau-tau_obs\n",
    "    Ntau=int(tau/dx)+1\n",
    "    K = np.zeros((nx, nx))\n",
    "    result = 0\n",
    "    for i in range(nx-2, -1, -1):\n",
    "        result += (f[[i+1],[i+1]] + f[[i],[i]])*dx/2*(-1)\n",
    "        K[i,i] = result\n",
    "    for i in range(nx-2, -1, -1):\n",
    "        num = nx - i\n",
    "        A1 = np.diag([-2]*num) + np.diag([1]*(num-1),1)\n",
    "        A1[[0],[0]] = 1\n",
    "        A1[[0],[1]] = 0\n",
    "        A1[[-1],[-1]] = 1\n",
    "\n",
    "        A121=np.zeros((num,num))\n",
    "        A122=np.zeros((num,num))\n",
    "        A121[1:num-1,0:num-1]= f.T[i+1:i-1+num,i:i-1+num]\n",
    "        A122[0:num-1,0:num-1] = dx*cof_int_0_x[0:num-1,0:num-1] \n",
    "        A1 = A1+ A121*A122\n",
    "        B1=np.zeros((num,1))\n",
    "        B1[[0],[0]] = K[[i],[i]]\n",
    "        B1[1:num-1,0] =-K[[i+1],i+1:nx-1].reshape((num-2)) +(dx*f[i,i+1:nx-1]).reshape((num-2))\n",
    "        if i+ Ntau<nx:\n",
    "            B1[num-1,0]=sum(cof_int_x_1[i+Ntau-1,:]*K[i+Ntau-1,:]*c)-c[i+Ntau-1]\n",
    "        else:\n",
    "            B1[num-1,0]=0\n",
    "        D=np.linalg.solve(A1,B1)\n",
    "        K[[i],i:nx]=D.T\n",
    "\n",
    "    J=np.zeros((nx, nx))\n",
    "    c_matrix=np.repeat(c[np.newaxis,:], nx, 0)\n",
    "    J[0:nx,0]=np.sum(cof_int_x_1*c_matrix*K, axis=1)-c[0:nx]\n",
    "    AJ = np.diag([k+1]*nx) + np.diag([-1]*(nx-1),-1)\n",
    "    AJ[0,0]=1\n",
    "    for i in range(nx-2, -1, -1):\n",
    "        BJ=np.zeros((nx,1))\n",
    "        BJ[0,0]=J[i,0]\n",
    "        BJ[1:nx,0]=k*J[i+1,1:nx]\n",
    "        J[[i],0:nx]=(np.linalg.solve(AJ,BJ)).T\n",
    "    \n",
    "    L=np.zeros((nx, nx))\n",
    "    L[0:nx,0]=J[0:nx,-1]\n",
    "    AL = np.diag([tau_obs+1]*nx) + np.diag([-1]*(nx-1),-1)\n",
    "    AL[0,0]=1\n",
    "    for i in range(nx-2, -1, -1):\n",
    "        BL=np.zeros((nx,1))\n",
    "        BL[0,0]=L[i,0]\n",
    "        BL[1:nx,0]=tau_obs*L[i+1,1:nx]\n",
    "        L[[i],0:nx]=(np.linalg.solve(AL,BL)).T\n",
    "    return K, L, J\n",
    "\n",
    "def fastObserverGainCalc(f, tau_obs, a, x, cof_int_x_1):\n",
    "    nx = len(x) \n",
    "    dx = x[2] - x[1]\n",
    "    F1 = np.zeros((nx, nx))\n",
    "    result = 0\n",
    "    for i in range(1, nx, 1):\n",
    "        result += (f[[i-1],[i-1]] + f[[i],[i]])*dx/2*(-1/a)\n",
    "        F1[i,i] = result\n",
    "    for j in range(2, nx, 1):\n",
    "        num = j\n",
    "        CC1 = np.diag([2]*num) + np.diag([-1]*(num-1),-1)\n",
    "        CC1[[-1],[num-2]] = 0\n",
    "        CC1[[-1],[num-1]] = 1\n",
    "        CC21=np.zeros((num,num))\n",
    "        CC22=np.zeros((num,num))\n",
    "        CC21= f[1:1+num,1:1+num]\n",
    "        CC22 = -(dx/a)*cof_int_x_1[nx-j:nx,nx-j:nx]\n",
    "        CC = CC1+ CC21*CC22 \n",
    "        DD=np.zeros((num,1))\n",
    "        DD[-1, 0] = F1[j,j]\n",
    "        DD[0:num-1,0] = F1[1:j,j-1].reshape((num-1)) -(dx/a*f[1:j,j]).reshape((num-1))\n",
    "        D=np.linalg.solve(CC,DD)\n",
    "        D2=np.dot(np.linalg.inv(CC),DD)\n",
    "        F1[1:j+1,j]=D.T\n",
    "\n",
    "    F23 = np.zeros((nx, nx))\n",
    "    F23[:,-1]=a*tau_obs*F1[:,-1]\n",
    "    # EE1 = np.diag([1+a*tau_obs]*(nx-1)) + np.diag([-a*tau_obs]*(nx-2),-1)\n",
    "    # EE21 = -dx*tau_obs*cof_int_x_1[1:nx,1:nx]\n",
    "    # EE22 = f[1:nx,1:nx]\n",
    "    EE = np.diag([1+a*tau_obs]*(nx-1)) + np.diag([-a*tau_obs]*(nx-2),-1)\\\n",
    "        -(dx*tau_obs*cof_int_x_1[1:nx,1:nx]) * f[1:nx,1:nx]\n",
    "    EE_inv = np.linalg.inv(EE)\n",
    "    for j in range(nx-2,-1,-1):\n",
    "        F23[1:nx,j] =  np.dot(EE_inv, F23[1:nx,j+1])\n",
    "    \n",
    "    Q1 = -F23[:,0]/tau_obs\n",
    "    Q2 = -np.flipud(F23[-1,:])\n",
    "    return F1, F23, Q1, Q2\n",
    "\n",
    "def solvePDE(tau, tau_obs, c, f, Kbud, Lbud, Jbud, init_condition, x, t, printFreq=500):\n",
    "    k=tau-tau_obs\n",
    "    nx = len(x)\n",
    "    nt = len(t)\n",
    "    dx=x[1]-x[0]\n",
    "    dt=t[1]-t[0]\n",
    "    uu = np.zeros((nt, 3*nx))\n",
    "    uu[0,:] = init_condition\n",
    "    for i in range(1, nt):\n",
    "        if i%int(1000) == 0:\n",
    "            print(\"Completed:\", i, \"/\", nt, flush=True)\n",
    "            \n",
    "        uu[i][0] = solveControl(uu[i-1], Kbud, Lbud, Jbud, nx, dx,tau_obs,k)\n",
    "        fres = np.zeros(nx)\n",
    "        for j in range(1, nx):\n",
    "            fres[j] = sum(f[j][j:nx]*uu[i-1][j:nx])*dx-f[j][j]*uu[i-1][j]*dx/2-f[j][nx-1]*uu[i-1][nx-1]*dx/2\n",
    "        uu[i][2*nx-1]=uu[i-1][nx-1]\n",
    "        uu[i][nx:2*nx-1] = uu[i-1][nx:2*nx-1]+dt/(tau_obs*dx)*(uu[i-1][nx+1:2*nx]-uu[i-1][nx:2*nx-1])\n",
    "        uu[i][3*nx-1]=uu[i-1][nx]\n",
    "        uu[i][2*nx:3*nx-1] = uu[i-1][2*nx:3*nx-1]+dt/(k*dx)*(uu[i-1][2*nx+1:3*nx]-uu[i-1][2*nx:3*nx-1])\n",
    "        uu[i][1:nx] = uu[i-1][1:nx] - dt/dx*(uu[i-1][1:nx] - uu[i-1][0:nx-1]) + dt*fres[1:nx] + dt*c[1:nx]*uu[i-1][nx]\n",
    "    return uu\n",
    "\n",
    "def solvePDEwithObse(tau, tau_obs,  c, f, Kbud, Lbud, Jbud,  Q1, Q2, init_condition, init_condition_obs, x, t, printFreq):\n",
    "    ## tau is state delay\n",
    "    ## tau_obs is sensor delay\n",
    "    k=tau-tau_obs\n",
    "    nx = len(x) \n",
    "    dx = x[2] - x[1]\n",
    "    nt = len(t)\n",
    "    dt = t[1]-t[0] \n",
    "    ###### initialization\n",
    "    u = np.zeros((nt, 3*nx))\n",
    "    u_est = np.zeros((nt, 3*nx)) \n",
    "    u[0,:] = init_condition\n",
    "    u_est[0,:] = init_condition_obs\n",
    "    print(\"Solving PDE... Timesteps Needed:\", nt, flush=True) \n",
    "    for i in range(1,nt,1):\n",
    "        if i%int(printFreq) == 0:\n",
    "            print(\"Completed:\", i, \"/\", nt, flush=True)\n",
    "        u[i,0] = sum(Kbud*u_est[i-1,0:nx]*dx)   \\\n",
    "            - Kbud[0]*u_est[i-1,0]*dx/2 - Kbud[nx-1]*u_est[i-1,nx-1]*dx/2 \\\n",
    "            + sum(tau_obs*Lbud*u_est[i-1,nx:2*nx]*dx )  \\\n",
    "            - tau_obs*Lbud[0]*u_est[i-1,nx]*dx/2 \\\n",
    "            - tau_obs*Lbud[nx-1]*u_est[i-1,2*nx-1]*dx/2 \\\n",
    "            + sum(k*Jbud*u_est[i-1,2*nx:3*nx]*dx ) \\\n",
    "            - k*Jbud[0]*u_est[i-1,2*nx]*dx/2 \\\n",
    "            - k*Jbud[nx-1]*u_est[i-1,3*nx-1]*dx/2  \n",
    "        fres = np.zeros(nx)\n",
    "        for j in range(1, nx):\n",
    "            fres[j] = sum(f[j,j:nx]*u[i-1,j:nx])*dx-f[j][j]*u[i-1][j]*dx/2-f[j][nx-1]*u[i-1][nx-1]*dx/2\n",
    "        \n",
    "        u[i][2*nx-1]=u[i-1][nx-1]\n",
    "        u[i][nx:2*nx-1] = u[i-1][nx:2*nx-1]+dt/(tau_obs*dx)*(u[i-1][nx+1:2*nx]-u[i-1][nx:2*nx-1])\n",
    "        u[i][3*nx-1]=u[i-1][nx]\n",
    "        u[i][2*nx:3*nx-1] = u[i-1][2*nx:3*nx-1]+dt/(k*dx)*(u[i-1][2*nx+1:3*nx]-u[i-1][2*nx:3*nx-1])\n",
    "        u[i][1:nx] = u[i-1][1:nx] - dt/dx*(u[i-1][1:nx] - u[i-1][0:nx-1]) + dt*fres[1:nx] + dt*c[1:nx]*u[i-1][2*nx]\n",
    "        \n",
    "        ##### observer part for \\hat x\n",
    "        u_est[i,0] = u[i,0]\n",
    "        fresu_est = np.zeros(nx)\n",
    "        for j in range(1, nx):\n",
    "            fresu_est[j] = sum(f[j,j:nx]*u_est[i-1,j:nx])*dx-f[j][j]*u_est[i-1][j]*dx/2-f[j][nx-1]*u_est[i-1][nx-1]*dx/2\n",
    "        \n",
    "        u_est[i,1:nx] = u_est[i-1,1:nx] - dt/dx*(u_est[i-1,1:nx] - u_est[i-1,0:nx-1]) \\\n",
    "            + dt*fresu_est[1:nx] + dt*c[1:nx]*u_est[i-1,2*nx] + dt*Q1[1:nx]*(u[i-1,nx] -u_est[i-1,nx])\n",
    "        ##### observer part for \\hat u1\n",
    "        u_est[i, 2*nx-1] = u_est[i,nx-1]\n",
    "        u_est[i,nx:2*nx-1] = u_est[i-1,nx:2*nx-1] + dt/(tau_obs*dx)*(u_est[i-1,nx+1:2*nx]- u_est[i-1,nx:2*nx-1]) \\\n",
    "        + dt*Q2[0:nx-1]/tau_obs * (u[i-1,nx] -u_est[i-1,nx])\n",
    "        ##### observer part for \\hat u2\n",
    "        u_est[i, 3*nx-1] = u[i,nx]\n",
    "        u_est[i,2*nx:3*nx-1] = u_est[i-1,2*nx:3*nx-1] + dt/(k*dx)*(u_est[i-1,2*nx+1:3*nx]- u_est[i-1,2*nx:3*nx-1]) \n",
    "    return u, u_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time\n",
    "T = 15\n",
    "dt = 0.001\n",
    "nt = int(round(T/dt))+1\n",
    "temporal = np.linspace(0, T, nt)\n",
    "## space\n",
    "X = 1\n",
    "# dx = dt*a\n",
    "dx = 0.02\n",
    "nx = int(round(X/dx))+1\n",
    "spatial = np.linspace(0, X, nx)\n",
    "\n",
    "cof_int_x_1 = buildCof_int_x_1(spatial, dx)\n",
    "cof_int_0_x = buildCof_int_0_x(spatial, dx)\n",
    "\n",
    "## system parameters\n",
    "# tau = 1.8\n",
    "# tau_obs = 0.3\n",
    "# k=tau-tau_obs\n",
    "\n",
    "# c=1-spatial\n",
    "# f =buildF(spatial, 5, 3, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndata1 = 40 #tau_obs\n",
    "ndata2 = 40 #f\n",
    "ndata= ndata1*ndata2 \n",
    "epochs =300\n",
    "ntrain = 1440\n",
    "ntest = 160\n",
    "batch_size = 20\n",
    "gamma = 0.6\n",
    "learning_rate = 0.0001\n",
    "step_size= 50\n",
    "# modes=12\n",
    "# width=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset generation0504\n",
    "inpArr = []\n",
    "outArr1 = []\n",
    "outArr2 = []\n",
    "tauobsArr = []\n",
    "fArr = []\n",
    "cArr = []\n",
    "\n",
    "for i in range(ndata1):\n",
    "        tauobsArr.append(np.random.uniform(0.1, 0.6))\n",
    "for i in range(ndata2):\n",
    "        f = buildF(spatial, np.random.uniform(3, 6), 3, np.random.uniform(3, 6), 3)\n",
    "        fArr.append(f)\n",
    " \n",
    "jj=0\n",
    "\n",
    "for tau_obs in tauobsArr:\n",
    "        for f in fArr:\n",
    "                jj+=1\n",
    "                if jj % 100 == 0:\n",
    "                        print(\"Completed\", jj, \"/\", ndata)\n",
    "                \n",
    "                F1, F23, Q1, Q2 = fastObserverGainCalc(f, tau_obs, 1, spatial, cof_int_x_1)\n",
    "                        \n",
    "                tauobs_matrix=buildtau(nx,tau_obs)\n",
    "                tempin=np.concatenate([tauobs_matrix,f.reshape(1,-1)],axis=1)\n",
    "                # tempout1 = np.concatenate([F1.reshape(1,-1), F23.reshape(1,-1)],axis=1)\n",
    "                tempout2 = np.concatenate([Q1.reshape(1,-1), Q2.reshape(1,-1)],axis=1)\n",
    "                inpArr.append(tempin)\n",
    "                # outArr1.append(tempout1)\n",
    "                outArr2.append(tempout2)\n",
    "\n",
    "##########\n",
    "x = np.array(inpArr)\n",
    "# y1 = np.array(outArr1)\n",
    "y2 = np.array(outArr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(x.shape[0],2*nx*nx)\n",
    "# y1 = y1.reshape(y1.shape[0],2*nx*nx)\n",
    "y2 = y2.reshape(y2.shape[0],2*nx)\n",
    "np.savetxt(\"x_obs.dat\", x)\n",
    "# np.savetxt(\"y1_obs50_0705.dat\", y1)\n",
    "np.savetxt(\"y2_obs.dat\", y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpArr = np.loadtxt(\"x_obs.dat\", dtype=np.float32)\n",
    "outArr = np.loadtxt(\"y2_obs.dat\", dtype=np.float32)\n",
    "x = np.array(inpArr)\n",
    "y = np.array(outArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = []\n",
    "grids.append(np.linspace(0, 1, nx, dtype=np.float32))\n",
    "grid=np.array(grids, dtype=np.float32).T\n",
    "grid = torch.from_numpy(np.array(grid, dtype=np.float32)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=1)\n",
    "x_train = torch.from_numpy(x_train).cuda()\n",
    "y_train = torch.from_numpy(y_train).cuda()\n",
    "x_test = torch.from_numpy(x_test).cuda()\n",
    "y_test = torch.from_numpy(y_test).cuda()\n",
    "\n",
    "trainData = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "testData = DataLoader(TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False, generator=torch.Generator(device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchNet(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=2, out_channels=64,\n",
    "                       kernel_size=5, stride=2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                       kernel_size=5, stride=2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc1 = torch.nn.Linear(12800, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 256)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x, (x.shape[0], 2, self.shape, self.shape))\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6926913\n",
      "6926913\n"
     ]
    }
   ],
   "source": [
    "# Define a sequential torch network for batch and trunk. Can use COV2D which we will show later\n",
    "dim_x = 1\n",
    "# m = int(nx*(nx+1)/2)\n",
    "m = 2*nx*nx\n",
    "branchobs1 = BranchNet(nx)\n",
    "branchobs2 = BranchNet(nx) \n",
    "modelobs1 = dde.nn.DeepONetCartesianProd([m, branchobs1], [dim_x, 128,  256], \"relu\", \"Glorot normal\").cuda()\n",
    "modelobs2 = dde.nn.DeepONetCartesianProd([m, branchobs2], [dim_x, 128,  256], \"relu\", \"Glorot normal\").cuda() \n",
    "print(count_params(modelobs1))\n",
    "print(count_params(modelobs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "\t{'params': modelobs1.parameters(), 'lr': learning_rate,}, \n",
    "\t{'params': modelobs2.parameters(), 'lr': learning_rate,}\n",
    "\t])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6940090860007331 0.42595003214147353 0.3055953790899366\n",
      "50 0.736078798014205 0.017397229857670025 0.014980347060609347\n",
      "100 0.6534281359927263 0.0008882734796134173 0.0009534758151767165\n",
      "150 0.7171521919954102 0.00029999901123220404 0.00032652079456852335\n",
      "200 0.7749416369770188 0.0001276632585217562 0.0001549782741466288\n",
      "250 0.7952060859824996 7.167447966518618e-05 8.888264714499882e-05\n"
     ]
    }
   ],
   "source": [
    "# loss = nn.MSELoss()\n",
    "loss = torch.nn.SmoothL1Loss(reduction='mean', beta=1.0)\n",
    "\n",
    "train_lossArr = []\n",
    "test_lossArr = []\n",
    "time_Arr = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    modelobs1.train()\n",
    "    modelobs2.train()\n",
    "    t1 = default_timer()\n",
    "    train_loss = 0\n",
    "    for x, y in trainData:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        y1=y[:,0:nx]\n",
    "        y2=y[:,nx:2*nx]\n",
    "        optimizer.zero_grad()\n",
    "        out1 = modelobs1((x, grid))\n",
    "        out2 = modelobs2((x, grid))\n",
    "        lp = loss(out1.view(batch_size, -1), y1.view(batch_size, -1)) \\\n",
    "        + loss(out2.view(batch_size, -1), y2.view(batch_size, -1))  \n",
    "\n",
    "        lp.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += lp.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    modelobs1.eval()\n",
    "    modelobs2.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in testData:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            y1=y[:,0:nx]\n",
    "            y2=y[:,nx:2*nx]\n",
    "            out1 = modelobs1((x, grid))\n",
    "            out2 = modelobs2((x, grid))\n",
    "            test_loss += loss(out1.view(batch_size, -1), y1.view(batch_size, -1)).item() \\\n",
    "            +loss(out2.view(batch_size, -1), y2.view(batch_size, -1)).item() \n",
    "            \n",
    "    train_loss /= len(trainData)\n",
    "    test_loss /= len(testData)\n",
    "    \n",
    "    train_lossArr.append(train_loss)\n",
    "    test_lossArr.append(test_loss)\n",
    "    \n",
    "    t2 = default_timer()\n",
    "    time_Arr.append(t2-t1)\n",
    "    if ep%50 == 0:\n",
    "        print(ep, t2-t1, np.mean(train_lossArr[-50:]), np.mean(test_lossArr[-50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(width, fraction=1, subplots=(1, 1), height_add=0):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float or string\n",
    "            Document width in points, or string of predined document type\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    if width == 'thesis':\n",
    "        width_pt = 426.79135\n",
    "    elif width == 'beamer':\n",
    "        width_pt = 307.28987\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = height_add + fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n",
    "\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"times\",\n",
    "    # Use 10pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"font.size\": 10,\n",
    "    # Make the legend/bel fonts a little smaller\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(tex_fonts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Model Details\n",
    "plt.figure(figsize=(1000 / 300, 618 / 300), dpi=300)\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.plot(train_lossArr, label=\"Train Loss\",linewidth=1.5)\n",
    "plt.plot(test_lossArr, label=\"Test Loss\",linewidth=1.5)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(fontsize=\"8\")\n",
    "\n",
    "testLoss = 0\n",
    "trainLoss = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in trainData:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        y1=y[:,0:nx]\n",
    "        y2=y[:,nx:2*nx] \n",
    "        out1 = modelobs1((x, grid))\n",
    "        out2 = modelobs2((x, grid))\n",
    "        out1 = out1.reshape((out1.shape[0], out1.shape[1]))\n",
    "        out2 = out2.reshape((out2.shape[0], out2.shape[1]))\n",
    "        trainLoss += loss(out1.view(batch_size, -1), y1.view(batch_size, -1)).item() \\\n",
    "            +loss(out2.view(batch_size, -1), y2.view(batch_size, -1)).item()  \n",
    "        \n",
    "    for x, y in testData:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        y1=y[:,0:nx]\n",
    "        y2=y[:,nx:2*nx] \n",
    "        out1 = modelobs1((x, grid))\n",
    "        out2 = modelobs2((x, grid)) \n",
    "        out1 = out1.reshape((out1.shape[0], out1.shape[1]))\n",
    "        out2 = out2.reshape((out2.shape[0], out2.shape[1])) \n",
    "        testLoss += loss(out1.view(batch_size, -1), y1.view(batch_size, -1)).item() \\\n",
    "            + loss(out2.view(batch_size, -1), y2.view(batch_size, -1)).item()  \n",
    "    \n",
    "    \n",
    "print(\"Avg Epoch Time:\", sum(time_Arr)/len(time_Arr))\n",
    "print(\"Final Testing Loss:\", testLoss)\n",
    "print(\"Final Training Loss:\", trainLoss)\n",
    "plt.tick_params(labelsize=8)\n",
    "# plt.savefig('img/Qloos.eps', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1\n",
    "tau_obs = 0.5\n",
    "k=tau-tau_obs\n",
    "# c=1-spatial\n",
    "c=solveBetaFunction(spatial, 5, 1)\n",
    "c = c-c[-1]\n",
    "f =buildF(spatial, 5, 3, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshy, meshx = np.meshgrid(spatial, spatial)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "surf = ax.plot_surface(meshx, meshy, zeroToNan(f))\n",
    "ax.set_title(r\"$f(x,y)$\")\n",
    "\n",
    "fig_intep=plt.figure()\n",
    "plt.plot(spatial, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =buildF(spatial, 5, 3, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1, F23, Q1, Q2 = fastObserverGainCalc(f, tau_obs, 1, spatial, cof_int_x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K,L,J=fastKernelCalc(f, c, tau, tau_obs, spatial, cof_int_x_1, cof_int_0_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau_matrix=buildtau(nx,tau)\n",
    "tauobs_matrix=buildtau(nx,tau_obs)\n",
    "\n",
    "xdata=np.concatenate([tauobs_matrix,f.reshape(1,-1)],axis=1)\n",
    " \n",
    "xdata = np.array(xdata, dtype=np.float32)\n",
    "xdata = torch.from_numpy(xdata.reshape((1, 2*nx*nx))).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1learning = modelobs1((xdata, grid))\n",
    "Q1learning = Q1learning.detach().cpu().numpy().reshape(1, nx)\n",
    "Q2learning= modelobs2((xdata, grid))\n",
    "Q2learning = Q2learning.detach().cpu().numpy().reshape(1, nx)\n",
    " \n",
    "####\n",
    "# Q1learning=Q1learning.reshape(1,nx)\n",
    "# Q2learning=Q2learning.reshape(1,nx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_intep=plt.figure()\n",
    "plt.plot(spatial, Q1,label=r'$Q_1(0,q)$')\n",
    "plt.plot(spatial, Q1learning[0,:],label=r'$\\hat Q_1$')\n",
    "plt.legend(loc=\"upper left\")\n",
    "fig_intep=plt.figure()\n",
    "plt.plot(spatial, Q2 ,label=r'$Q_2$')\n",
    "plt.plot(spatial, Q2learning[0,:],label=r'$\\hat Q_2$')\n",
    "plt.legend(loc=\"upper left\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1='./Model/ObseTorchMode1.pth' \n",
    "path2='./Model/ObseTorchMode2.pth' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelobs1.state_dict(), path1)\n",
    "torch.save(modelobs2.state_dict(), path2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelobs1.load_state_dict(torch.load(path1))\n",
    "modelobs2.load_state_dict(torch.load(path2)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
